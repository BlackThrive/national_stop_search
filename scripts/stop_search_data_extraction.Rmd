---
title: "Untitled"
author: "Jolyon Miles-Wilson"
date: "22/11/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Packages
```{r}
packages <- c('tidyverse',
              'jsonify', # for reading json
              'leaflet', # for map
              'httr', # for http requests
              'data.table', # for unlisting
              'rgdal', # for geopackage
              'sf' # for geopackage
)
pkg_notinstall <- packages[!(packages %in% installed.packages()[,"Package"])]
lapply(pkg_notinstall, install.packages, dependencies = TRUE)
lapply(packages, library, character.only = TRUE)
```

# places from geopackage

```{r}
las <- read.csv("../data/places_la_to_country.csv")
#ogrListLayers("../data/bdline_gb.gpkg") # check layers
geo_data <- st_read("../data/bdline_gb.gpkg", layer = "district_borough_unitary") # extract layer of interest
geo_geom <- geo_data$geometry # get geometry columns
geo_geom_wgs84 <- st_transform(geo_geom, crs = "WGS84") # tranform to longitude/latitude
names(geo_geom_wgs84) <- geo_data$Name # add names

geo_geom_wgs84_2 <- vector(mode = "list", length = length(geo_geom_wgs84))
names(geo_geom_wgs84_2) <- geo_data$Name # add names

for(i in 1:length(geo_geom_wgs84)){
  for(j in 1:length(geo_geom_wgs84[[i]])){
    # for each LA, create just one list of lists that contains all coordinate pair lists
    # so that for LAs with multiple coordinate lists, each LA has a separate df for each list of coords
    geo_geom_wgs84_2[[i]][["coords"]][[j]] <- as.data.frame(geo_geom_wgs84[[i]][[j]][[1]])
    colnames(geo_geom_wgs84_2[[i]][["coords"]][[j]]) <- c("long","lat")

  }
  
  geo_geom_wgs84_2[[i]][["census_code"]] <- geo_data$Census_Code[i] # take census code
  
  # add la, county, region, and country names
  try(
    geo_geom_wgs84_2[[i]][["la"]] <- las[which(las$LAD19CD == geo_data$Census_Code[i]), "LAD19NM"] 
  )
  try(
    geo_geom_wgs84_2[[i]][["county"]] <- las[which(las$LAD19CD == geo_data$Census_Code[i]), "CTY19NM"]
  )
  try(
    geo_geom_wgs84_2[[i]][["region"]] <- las[which(las$LAD19CD == geo_data$Census_Code[i]), "RGN19NM"]
  )
  try(
    geo_geom_wgs84_2[[i]][["country"]] <- las[which(las$LAD19CD == geo_data$Census_Code[i]), "CTRY19NM"]
  )
  
  # report which LAs have missing values 
  if(is_empty(geo_geom_wgs84_2[[i]][["la"]])){
    print(paste0(names(geo_geom_wgs84_2)[i], " la missing (", i, ")"))
  }
  if(is_empty(geo_geom_wgs84_2[[i]][["county"]])){
    print(paste0(names(geo_geom_wgs84_2)[i], " county missing (", i, ")"))
  }
  if(is_empty(geo_geom_wgs84_2[[i]][["region"]])){
    print(paste0(names(geo_geom_wgs84_2)[i], " region missing (", i, ")"))
  }
  if(is_empty(geo_geom_wgs84_2[[i]][["country"]])){
    print(paste0(names(geo_geom_wgs84_2)[i], " country missing (", i, ")"))
  }
  # rename las with names from list from gov website
  try(
    names(geo_geom_wgs84_2)[i] <- geo_geom_wgs84_2[[i]][["la"]]
  )
}

# manually add missing values

geo_geom_wgs84_2[["West Northamptonshire"]][["la"]] <- "West Northamptonshire"
geo_geom_wgs84_2[["West Northamptonshire"]][["region"]] <- "East Midlands"
geo_geom_wgs84_2[["West Northamptonshire"]][["country"]] <- "England"

geo_geom_wgs84_2[["North Northamptonshire"]][["la"]] <- "North Northamptonshire"
geo_geom_wgs84_2[["North Northamptonshire"]][["region"]] <- "East Midlands"
geo_geom_wgs84_2[["North Northamptonshire"]][["country"]] <- "England"

geo_geom_wgs84_2[["Buckinghamshire"]][["la"]] <- "Buckinghamshire"
geo_geom_wgs84_2[["Buckinghamshire"]][["region"]] <- "South East"
geo_geom_wgs84_2[["Buckinghamshire"]][["country"]] <- "England"

coords <- geo_geom_wgs84_2
rm(geo_geom_wgs84_2)
rm(geo_geom_wgs84)
rm(geo_geom)
rm(geo_data)
```

# unlisting - may be unnecessary now. all below is now included in above function

```{r}
# coords <- geo_geom_wgs84_2
# # recursively unlist coordinates so that each element of list coontains a dataframe 
# # of long/lat coordinates
# coords_unlisted <- list()
# for(i in 1:length(coords)){
#   df <- as.data.frame(unlist(coords[[i]][["coords"]][[1]]))
#   colnames(df) <- c("long","lat")
#   coords_unlisted[[i]] <- list(coords = df, 
#                                la = coords[[i]][["la"]],
#                                county =  coords[[i]][["county"]],
#                                region = coords[[i]][["region"]],
#                                country = coords[[i]][["country"]])
#   names(coords_unlisted)[i] <- coords[[i]][["la"]]
# }

```

# map check
```{r}
coords_for_map <- coords[["Cornwall"]][["coords"]] # map wants long, lat

# this puts the coordinates in a form that leaflet can plot multiple polygons with
coord_string <- c()
for(i in 1:length(coords_for_map)){
  df <- rbind(coords_for_map[[i]], c(NA,NA)) # separate each set of coords with a row of NAs
  coord_string <- rbind(coord_string, df) # bind all sets together
}

df <- coords_for_map[[i]]

leaflet(as.matrix(coord_string)) %>% # leaflet only accepts as matrix
  addPolygons()  %>%
  addTiles() 
```

```{r}
coords_for_map <- coords[["Cornwall"]][["coords"]] # map wants long, lat

for(i in 1:length(coords_for_map)){
  iteration_coords <- coords_for_map[[i]]
  map <- leaflet(as.matrix(iteration_coords)) %>% 
    addPolygons() %>% 
    addTiles()
  show(map)
}

```


# area police api - current working version

```{r}
# Acquire Stop and Search data for a list of Local Authority (LA) areas over a 
# time period. 

# Arguments

## coord_list: List of areas of interest. Each element of list must be a data 
## frame with column names "lat" and "long". A separate function is available
## to create this list.

## most_recent_month: Numeric value specifying most recent month (e.g., 8 for August)

## most_recent_year (YYYY): Numeric value specifying most recent year (e.g., 2021)

## If one or both of most_recent_month/year is not specified, the function will 
## query Police API for the most recent update and use this as a start point.

## num_months_backwards: Number of months backwards for which data are required. 

## wait_time: Number of seconds to wait between retries of unsuccessful requests.

## max_tries: Maximum number of retries following an unsuccessful request. Default 
## is 'Inf' because usually all data are desired and unsuccessful requests are most
## likely timeouts that can be resolved by retrying.

# Value

## Output is a list containing 'results' and 'missing_entries'. 'results' contains
## the queried data in a dataframe. 'missing_entries' contains a list of LAs and
## their corresponding index in coord_list for which no data records exist for
## the specified time period.

la_search_police_api <- function(coord_list, 
                                 most_recent_month = NULL, 
                                 most_recent_year = NULL, 
                                 num_months_backwards = 12, 
                                 wait_time = 5, 
                                 max_tries = Inf){
  # initialise dataframes
  overall_output <- data.frame()
  no_entries_df <- data.frame(setNames(rep(list(NA), 2), c("Index","Name")))
  
  # h loop iterates over LAs
  for(h in 1:length(coord_list)){
    print(paste0("Started area ", h)) # report start (useful for debugging)
    
    la <- coord_list[[h]][["la"]] # LA name
    
    county <- coord_list[[h]][["county"]] # county name
    if(is_empty(county)){
      county <- NA # set NA if missing
    }
    
    region <- coord_list[[h]][["region"]] # region name
    if(is_empty(region)){
      region <- NA # set NA if missing
    }
    
    country <- coord_list[[h]][["country"]] # country name
    
    # get most recent update if most_recent data not specified
    if(is.null(most_recent_month) || is.null(most_recent_year)){ 
      # get most recent update from API:
      date <- httr::content(
        httr::GET("https://data.police.uk/api/crimes-street-dates"))[[1]][["date"]] 
      most_recent_month <- as.numeric(substr(date,6,7))
      most_recent_year <- as.numeric(substr(date,1,4))
    }
    else{
      most_recent_month <- most_recent_month
      most_recent_year <- most_recent_year
    }
    
    area_output <- data.frame() # initialise area output df
    
    # i loop iterates over the months required 
    for(i in 1:num_months_backwards){
      # format date to what is needed for API query ("yyyy-mm")
      if(i == 1){ # set values for first iteration
        month_num <- most_recent_month
        year <- most_recent_year
      }
      else{ # subsequent iterations
        month_num <- month_num - 1 # backwards a month each iteration
        if(month_num %% 12 == 0){ # if reach a new year, start months from 12 again
          month_num <- 12
          year <- year - 1 # backwards a year
        }
      }
      if(month_num < 10){ # paste 0 for months lower than 10
        month <- paste("0", month_num, sep = "")
      }
      else{
        month <- month_num
      }
      
      date <- paste(year, "-", month, sep = "") # combine dates into one string
      
      # j loop iterates over the coordinate sets within each LA and creates a
      # polygon string to be searched, and then submits the query.
      # Most LAs have only one coordinate set, but some have multiple (e.g., 
      # those that include islands). The function therefore needs to search 
      # each coordinate set within a LA separately.
      coord_string <- c() # initialise vector for coord string
      for(j in 1:length(coord_list[[h]][["coords"]])){
        # set this iteration's coordinate set:
        area_coords <- coord_list[[h]][["coords"]][[j]]
        # combine coord strings into format required by API:
        coord_string <- paste0(area_coords$lat,",",area_coords$long, collapse = ":") 
        
        # create body for post request
        body <- list("poly" = coord_string,
                     "date" = date)
        # search API for this coordinate set and date:
        post_request <- httr::POST("https://data.police.uk/api/stops-street?", body = body)
        
        # if search quota reached, break (shouldn't be an issue but just in case)
        if(post_request[["status_code"]] == 429){
          print("Quota reached. Abandoning request.")
          break
        }
        else{
          # if the request didn't succeed, wait some time ('wait_time') and 
          # keep trying up until 'max_tries' attempts.
          attempt <- 1
          while(post_request[["status_code"]] != 200 && attempt <= max_tries){ 
            print(paste0("Server error. Trying again (", attempt,")"))
            Sys.sleep(wait_time) # wait some time before trying again
            try(
              post_request <- httr::POST("https://data.police.uk/api/stops-street?", body = body)
            )
            # if search quota reached, break (shouldn't be an issue but just in case)
            if(post_request[["status_code"]] == 429){ 
              print("Quota reached. Abandoning request.")
              break
            }
            attempt <- attempt + 1
          }
        }
        
        # get data from results of query
        df <- httr::content(post_request) 
        # unlist data and convert to dataframe:
        df_2 <- lapply(df, unlist)
        df_3 <- do.call(bind_rows, df_2)
        df_3$coord_set <- j # record which coordinate set data is from
        
        # add results of this coordinate set iteration (j) to the output for 
        # this LA iteration (h). Use bindrows for (high) possibility that columns
        # from different iterations will be in different order/missing
        area_output <- bind_rows(area_output, df_3) 
        
        cat("\014") # clear console 
        # report overall (i.e., LA) progress
        print(paste0("Working... LA ", h, " of ", length(coord_list), 
                     " (", 
                     round(100 * (h / length(coord_list)), 2), "%)"))
        # report month progress
        print(paste0("Working... Month ", i, " of ", num_months_backwards, 
                     " (", date, ")"))
        # report coordinate set progress
        print(paste0("Working... ", j, " of ", 
                     length(coord_list[[h]][["coords"]]), 
                     " coordinate sets retrieved"))

        
      } # coordinate set loop (j) ends
      

      
    } # month loop (i) ends
    
    # If there were no records for this LA, record the LA iteration number
    # and name, then proceed to the next LA
    if(nrow(area_output) == 0){
      if(is.na(no_entries_df[1,1])){ # if first occurrence, replaces NAs 
        no_entries_df[1,] <- c(h, la)
      }
      else{ # rbind subsequent occurrences
        no_entries_df <- rbind(no_entries_df, c(h, la))        
      }
      print(paste0("No records for ", la))
      next # proceed to next LA
    }
    
    # add columns for LA name, county, region, country, and the iteration index
    # for the LA (useful for quickly identifying which LA the function reached 
    # if it breaks unexpectedly)
    area_output$la <- la
    area_output$county <- county
    area_output$region <- region
    area_output$country <- country
    area_output$index <- h
    
    # move index and location data to front of df
    area_output <- area_output %>%
      select(index, la, county, region, country, everything())
    overall_output <- bind_rows(overall_output, area_output)
  
    # create a temporary output list and save it every time a LA completes, so
    # that there is a backup in case function breaks. Saves to same folder as
    # script
    save_progress <- list(result = overall_output,
                          missing_entries = no_entries_df)
    save(save_progress, file = "./save_progress.Rdata")
  } # LA loop (h) ends
  
  # return output. 'result' is the data. 'missing_entries' provides a list of
  # LAs that are missing from the data because there were no records for the 
  # LA in the specified time period.
  return(list(result = overall_output,
              missing_entries = no_entries_df))
}


# pick out areas with multiple poly areas
poly_list <- matrix(ncol = 2)
for(i in 1:length(coords)){
  if(length(coords[[i]][["coords"]]) > 1)
    poly_list <- rbind(poly_list, c(i, length(coords[[i]][["coords"]])))
}
poly_list <- poly_list[-c(1),] # get rid of NA

poly_areas <- coords[c(poly_list)]

below_100 <- poly_list[which(poly_list[,2] < 100),] # pick areas that have fewr htan 100 polygons

this_list <- coords[c(below_100[,1])] # choose subset of areas

this_list <- coords[c(124:200)]
data <- retrieve_area_data(this_list, num_months_backwards = 12, most_recent_month = 10, most_recent_year = 2021)

save(data, file = "../data/1_to_100.Rdata")
df <- data[[1]]

df <- save_progress[[1]]
unique(df$index)
to_save <- df[-c(which(df$index == 24)),]
save(to_save, file = "../data/101_to_123.Rdata")

save(df, file = "example_area_from_alt_coord_set.Rdata")
unique(df$coord_set)

data_2 <- data[[1]]
save(df, file = "../data/las_124_to_200_df.Rdata")
df <- data[[1]]

df_2 <- df[10600:10700,]
data_2$age_range <- unlist(data_2$age_range)
# 
# data_matrix <- as.matrix(data_2)
# 
# save(data, file = "../data/las_301_to_363.Rdata")
# 
# # write_csv(data_matrix, file = "../data/test_save_2.csv")
# write.csv(data_2, file = "../data/test.csv")
```

```{r}
this_list <- coords[c(301:363)]
data <- la_search_police_api(this_list, num_months_backwards = 12, most_recent_month = 10, most_recent_year = 2021)

save(data, file = "../data/las_301_to_363_list.Rdata")

df <- data[[1]]
save(df, file = "../data/las_301_to_363_df.Rdata")
```


```{r}
# for finding just one area?
temp_func <- function(coord_string, 
                               most_recent_month = 10, 
                               most_recent_year = 2021, 
                               num_months_backwards = 12, 
                               wait_time = 5, 
                               max_tries = Inf){
  area_output <- data.frame()
    for(i in 1:num_months_backwards){
      if(i == 1){ # set values for first iteration
        month_num <- most_recent_month
        year <- most_recent_year
      }
      else{ # subsequent iterations
        month_num <- month_num - 1 # backwards a month each iteration
        if(month_num %% 12 == 0){ # if reach a new year, start months from 12 again
          month_num <- 12
          year <- year - 1 # backwards a year
        }
      }
      if(month_num < 10){ # paste 0 for months lower than 10
        month <- paste("0", month_num, sep = "")
      }
      else{
        month <- month_num
      }
      
      
      date <- paste(year, "-", month, sep = "") # combine dates into format for api
      body <- list("poly" = coord_string,
                   "date" = date)
      post_request <- httr::POST("https://data.police.uk/api/stops-street?", body = body) # POST request
      if(post_request[["status_code"]] == 429){ # if quota reached, break
        print("Quota reached. Abandoning request.")
        break
      }
      else{
        attempt <- 1
        while(post_request[["status_code"]] != 200 && attempt <= max_tries){ 
          print(paste0("Server error. Trying again (", attempt,")"))
          Sys.sleep(wait_time) # wait some time before trying again
          try(
            post_request <- httr::POST("https://data.police.uk/api/stops-street?", body = body)
          )
          if(post_request[["status_code"]] == 429){ # if quota reached, break
            print("Quota reached. Abandoning request.")
            break
          }
          attempt <- attempt + 1
        }
      }

      df <- httr::content(post_request) # get content from response
      df_2 <- lapply(df, unlist)
      df_3 <- do.call(bind_rows, df_2) # convert to df
      area_output <- bind_rows(area_output, df_2) # add to dataframe. use bindrows for possibility of non-matching variables
    }
  return(area_output)                    
           }

highlands_data <- temp_func(coord_string)

highlands_data$la <- "Highlands"
highlands_data$county <- NA 
highlands_data$region <- NA
highlands_data$country <- "Scotland"

highlands_data <- highlands_data %>%
  select(la, county, region, country, everything())

save(highlands_data, file = "../data/las_123.Rdata")
```


```{r}
# for finding just one area?
temp_func <- function(coord_string, 
                               most_recent_month = 10, 
                               most_recent_year = 2021, 
                               num_months_backwards = 12, 
                               wait_time = 5, 
                               max_tries = Inf){
  area_output <- data.frame()
    for(i in 1:num_months_backwards){
      if(i == 1){ # set values for first iteration
        month_num <- most_recent_month
        year <- most_recent_year
      }
      else{ # subsequent iterations
        month_num <- month_num - 1 # backwards a month each iteration
        if(month_num %% 12 == 0){ # if reach a new year, start months from 12 again
          month_num <- 12
          year <- year - 1 # backwards a year
        }
      }
      if(month_num < 10){ # paste 0 for months lower than 10
        month <- paste("0", month_num, sep = "")
      }
      else{
        month <- month_num
      }
      
      
      date <- paste(year, "-", month, sep = "") # combine dates into format for api
      body <- list("poly" = coord_string,
                   "date" = date)
      post_request <- httr::POST("https://data.police.uk/api/stops-street?", body = body) # POST request
      if(post_request[["status_code"]] == 429){ # if quota reached, break
        print("Quota reached. Abandoning request.")
        break
      }
      else{
        attempt <- 1
        while(post_request[["status_code"]] != 200 && attempt <= max_tries){ 
          print(paste0("Server error. Trying again (", attempt,")"))
          Sys.sleep(wait_time) # wait some time before trying again
          try(
            post_request <- httr::POST("https://data.police.uk/api/stops-street?", body = body)
          )
          if(post_request[["status_code"]] == 429){ # if quota reached, break
            print("Quota reached. Abandoning request.")
            break
          }
          attempt <- attempt + 1
        }
      }

      df <- httr::content(post_request) # get content from response
      df_2 <- lapply(df, unlist)
      df_3 <- do.call(bind_rows, df_2) # convert to df
      area_output <- bind_rows(area_output, df_2) # add to dataframe. use bindrows for possibility of non-matching variables
    }
  return(area_output)                    
           }

highlands_data <- temp_func(coord_string)

highlands_data$la <- "Highlands"
highlands_data$county <- NA 
highlands_data$region <- NA
highlands_data$country <- "Scotland"

highlands_data <- highlands_data %>%
  select(la, county, region, country, everything())

save(highlands_data, file = "../data/las_123.Rdata")
```



# next steps 

- is there any way to use "no location" data to supplement datasets?
- include force variable. there is a force boundary thing that might work
- need to provide some way of weighting, or at least providing, information about 
the amount of data there is for each LA. for example, some las are missing some months, and if we were to compare across LAs, this would have the effect of making some LAs look better than others simply because there's less data. this could be done by elaborating on the no_entries coding
